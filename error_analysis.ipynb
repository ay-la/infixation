{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e25264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6991a7",
   "metadata": {},
   "source": [
    "# Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a243b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_df(filename):\n",
    "    df = pd.read_json(filename).swapaxes(\"index\",\"columns\")\n",
    "    \n",
    "    # use integer indices and set words to new column\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={'index': 'word'})\n",
    "    df['index'] = range(len(df))\n",
    "    df = df.set_index('index')\n",
    "    \n",
    "    # convert T/F of 'predicted_correctly' to int\n",
    "    df['predicted_correctly'] = df['predicted_correctly'].astype(int)\n",
    "    \n",
    "    return df \n",
    "\n",
    "\n",
    "def clean_result(df_row):\n",
    "    result = df_row['result']\n",
    "    result_str = result.lower()\n",
    "    punctuations = string.punctuation.replace(\"-\", \"\")\n",
    "    clean_result = ''.join(char for char in result_str if char not in punctuations)\n",
    "    clean_result = clean_result.split()\n",
    "    return clean_result\n",
    "\n",
    "\n",
    "# Infix-specific functions to use for df.apply()\n",
    "def cr_fuckin(df_row):\n",
    "    cr = clean_result(df_row)\n",
    "    return [word for word in cr if 'fuckin' in word][0]\n",
    "    \n",
    "\n",
    "def cr_iz(df_row):\n",
    "    cr = clean_result(df_row)\n",
    "    return [word for word in cr if '-iz-' in word][0]\n",
    "\n",
    "\n",
    "def cr_diddly(df_row):\n",
    "    cr = clean_result(df_row)\n",
    "    return [word for word in cr if 'diddly' in word][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c6fbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expletive_results_path = 'results/text-davinci-003_results/fuckin/fuckin_5shot_v0.json'\n",
    "# iz_results_path = 'results/text-davinci-003_results/iz/iz_3shot_v1.json'\n",
    "# diddly_results_path = 'results/text-davinci-003_results/diddly/diddly_3shot_v1.json'\n",
    "\n",
    "expletive_results = create_new_df(expletive_results_path)\n",
    "# iz_results = create_new_df(iz_results_path)\n",
    "# diddly_results = create_new_df(diddly_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee9f4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expletive_results['clean_result'] = expletive_results.apply(cr_fuckin, axis=1)\n",
    "# iz_results['clean_result'] = iz_results.apply(cr_iz, axis=1)\n",
    "# diddly_results['clean_result'] = diddly_results.apply(cr_diddly, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a16f7c",
   "metadata": {},
   "source": [
    "# Error 1: Does it infix?\n",
    "- If you remove the infix from the output, is the input word retained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "439005ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infix_at_edge(word, infix):\n",
    "    pattern = r\"(^(-?\" + re.escape(infix) + \"-?))|((-?\" + re.escape(infix) + \"-?)$)\"\n",
    "    return bool(re.search(pattern, word))\n",
    "\n",
    "def infix_eval(infix, results_df):\n",
    "    '''\n",
    "    Checks if infix is inserted to the start or end of the test word.\n",
    "    If not, checks if the model output retains integrity of the base word \n",
    "    after infixing (no extra deletions or insertions).\n",
    "    Returns the percent accuracy of outputs that adhere to these rules.\n",
    "    '''\n",
    "    infix_no_dash = infix.replace('-', '')\n",
    "    model_outputs = results_df['clean_result'].tolist()\n",
    "    originals = results_df['word'].tolist()\n",
    "    \n",
    "    infix_results = []\n",
    "    \n",
    "    for i in range(len(results_df)):\n",
    "        if infix_at_edge(model_outputs[i], infix_no_dash):\n",
    "            infix_results.append(False)\n",
    "        else:\n",
    "            remove_infix = model_outputs[i].replace(infix, '')\n",
    "            remove_infix_no_dash = model_outputs[i].replace(infix_no_dash, '')\n",
    "            \n",
    "            original = originals[i].strip().lower()\n",
    "            \n",
    "            does_infixation = (remove_infix == original) or (remove_infix_no_dash == original)\n",
    "            \n",
    "            infix_results.append(does_infixation)\n",
    "        \n",
    "    return sum(infix_results)/len(results_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "656c5ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infix_eval('-fuckin-', expletive_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad43e670",
   "metadata": {},
   "source": [
    "# Error 2: Does it respect syllable boundaries?\n",
    "- Is it actually inserting the infix in between syllables (even if they're the wrong ones)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce16ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load relevant dataset NOTE: THESE ARE NOT THE RESULTS\n",
    "expletive_path = 'data/infix_dataset/expletive_data.csv'\n",
    "expletive_dataset = pd.read_csv(expletive_path, index_col=0)\n",
    "full_dataset = pd.read_csv('data/syllable_data/all_syllable_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f23a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_eval(infix, model_output, actual_syllables):\n",
    "    '''\n",
    "    Determines if infixation occurs between syllables.\n",
    "    This method of evaluation only really applies to expletive and diddly infixation\n",
    "    '''\n",
    "    model_output = model_output.lower().split(infix)\n",
    "    actual_syllables = [s.lower() for s in actual_syllables]\n",
    "    \n",
    "    if model_output[0] == actual_syllables[0]:\n",
    "        return True\n",
    "    else:\n",
    "        concat = ''\n",
    "        actual_syllables.append('') # padding for loop\n",
    "        \n",
    "        for s in actual_syllables:\n",
    "            if model_output[0] == concat:\n",
    "                return True\n",
    "            else:\n",
    "                concat += s\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b5c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_results = []\n",
    "originals = expletive_results['word'].tolist()\n",
    "\n",
    "for i in range(len(expletive_results)):\n",
    "    try:\n",
    "        row = full_dataset.loc[full_dataset['word']==originals[i].strip().upper()]\n",
    "        result = expletive_results[i]\n",
    "        correct_syllables = ast.literal_eval(full_dataset.loc[row.index[0], 'syllables'])\n",
    "        correct_stress = ast.literal_eval(full_dataset.loc[row.index[0], 'stress_pattern'])\n",
    "\n",
    "        syllable_results.append(syllable_eval('-fuckin-', result, correct_syllables))\n",
    "        \n",
    "    except IndexError:\n",
    "        print(\"Word not found in dataset:\", originals[i])\n",
    "\n",
    "sum(syllable_results)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8b00cc",
   "metadata": {},
   "source": [
    "# Error 3: Does it respect stress pattern?\n",
    "- Even if it is inserting between syllables, is it doing it between the right ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80ceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress_eval(infix, model_output, stress_pattern):\n",
    "    '''\n",
    "    If the second half of the model output (the part following the infix) matches\n",
    "    the concatenation of syllables following the primary stress, the model has \n",
    "    infixed at the right spot.\n",
    "    This code assumes that primary stress is occurring internally and that there is only one.\n",
    "    '''\n",
    "    model_output = model_output.lower().split(infix)\n",
    "    index = 0\n",
    "    for i in range(len(stress_pattern)):\n",
    "        if stress_pattern[i][1] == '1':\n",
    "            index = i\n",
    "            break\n",
    "    postfix = stress_pattern[index:]\n",
    "    postfix = [p[0].lower() for p in postfix]\n",
    "    postfix = ''.join(postfix)\n",
    "    \n",
    "    # print(model_output[-1], postfix, stress_pattern)\n",
    "    \n",
    "    if model_output[-1] == postfix:\n",
    "        return True\n",
    "    else:\n",
    "        return False      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_results = []\n",
    "\n",
    "for i in range(len(expletive_results)):\n",
    "    try:\n",
    "        row = full_dataset.loc[full_dataset['word']==originals[i].strip().upper()]\n",
    "        result = expletive_results[i]\n",
    "        correct_stress = ast.literal_eval(full_dataset.loc[row.index[0], 'stress_pattern'])\n",
    "        \n",
    "        stress_results.append(stress_eval('-fuckin-', result, correct_stress))\n",
    "        \n",
    "    except IndexError:\n",
    "        print(\"Word not found in dataset:\", originals[i])\n",
    "        \n",
    "sum(stress_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e989de04",
   "metadata": {},
   "source": [
    "# tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98133398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# text-davinci-002 and 003 use p50k_base\n",
    "encoding = tiktoken.encoding_for_model('text-davinci-003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_bytes(word):\n",
    "    token_integers = encoding.encode(word)\n",
    "    token_bytes = [encoding.decode_single_token_bytes(token) for token in token_integers]\n",
    "    return token_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e38411",
   "metadata": {},
   "source": [
    "tiktoken_df = expletive_results[['word', 'correct_infix', 'clean_result', 'predicted_correctly']]\n",
    "tiktoken_df['tokens'] = tiktoken_df['word'].apply(get_token_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktoken_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e02ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
